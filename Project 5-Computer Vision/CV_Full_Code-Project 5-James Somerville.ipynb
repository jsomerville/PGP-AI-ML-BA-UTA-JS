{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9VXT5unCaBd"
      },
      "source": [
        "# Introduction to Computer Vision: Plant Seedlings Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZgcS1MyVGZp"
      },
      "source": [
        "## Problem Statement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCxSmokWEKUJ"
      },
      "source": [
        "### Context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2mC12JhVNGp"
      },
      "source": [
        "In recent times, the field of agriculture has been in urgent need of modernizing, since the amount of manual work people need to put in to check if plants are growing correctly is still highly extensive. Despite several advances in agricultural technology, people working in the agricultural industry still need to have the ability to sort and recognize different plants and weeds, which takes a lot of time and effort in the long term. The potential is ripe for this trillion-dollar industry to be greatly impacted by technological innovations that cut down on the requirement for manual labor, and this is where Artificial Intelligence can actually benefit the workers in this field, as **the time and energy required to identify plant seedlings will be greatly shortened by the use of AI and Deep Learning.** The ability to do so far more efficiently and even more effectively than experienced manual labor, could lead to better crop yields, the freeing up of human inolvement for higher-order agricultural decision making, and in the long term will result in more sustainable environmental practices in agriculture as well.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_I9gQJMVWL_"
      },
      "source": [
        "### Objective"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkD5j4o4VYYQ"
      },
      "source": [
        "The aim of this project is to Build a Convolutional Neural Netowrk to classify plant seedlings into their respective categories."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZq8uFtOVfnm"
      },
      "source": [
        "### Data Dictionary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75fTG3prVjUU"
      },
      "source": [
        "The Aarhus University Signal Processing group, in collaboration with the University of Southern Denmark, has recently released a dataset containing **images of unique plants belonging to 12 different species.**\n",
        "\n",
        "- The dataset can be download from Olympus.\n",
        "- The data file names are:\n",
        "    - images.npy\n",
        "    - Labels.csv\n",
        "- Due to the large volume of data, the images were converted to the images.npy file and the labels are also put into Labels.csv, so that you can work on the data/project seamlessly without having to worry about the high data volume.\n",
        "\n",
        "- The goal of the project is to create a classifier capable of determining a plant's species from an image.\n",
        "\n",
        "**List of Species**\n",
        "\n",
        "- Black-grass\n",
        "- Charlock\n",
        "- Cleavers\n",
        "- Common Chickweed\n",
        "- Common Wheat\n",
        "- Fat Hen\n",
        "- Loose Silky-bent\n",
        "- Maize\n",
        "- Scentless Mayweed\n",
        "- Shepherds Purse\n",
        "- Small-flowered Cranesbill\n",
        "- Sugar beet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9B4COveVqnm"
      },
      "source": [
        "### **Note: Please use GPU runtime on Google Colab to execute the code faster.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqFzmTb0BKKW"
      },
      "source": [
        "## Importing necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JAkYVkhPb0p7"
      },
      "outputs": [],
      "source": [
        "# Installing the libraries with the specified version.\n",
        "# uncomment and run the following line if Google Colab is being used\n",
        "!pip install tensorflow==2.15.0 scikit-learn==1.2.2 seaborn==0.13.1 matplotlib==3.7.1 numpy==1.25.2 pandas==2.0.3 opencv-python==4.8.0.76 -q --user"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lw8IuZwV-PAL"
      },
      "outputs": [],
      "source": [
        "# Installing the libraries with the specified version.\n",
        "# uncomment and run the following lines if Jupyter Notebook is being used\n",
        "#!pip install tensorflow==2.13.0 scikit-learn==1.2.2 seaborn==0.11.1 matplotlib==3.3.4 numpy==1.24.3 pandas==1.5.2 opencv-python==4.8.0.76 -q --user"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbFXvdwks2iR"
      },
      "source": [
        "**Note**: *After running the above cell, kindly restart the notebook kernel and run all cells sequentially from the start again.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "FsytN_Rps2Cz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np                                                                               # Importing numpy for Matrix Operations\n",
        "import pandas as pd                                                                              # Importing pandas to read CSV files\n",
        "import matplotlib.pyplot as plt                                                                  # Importting matplotlib for Plotting and visualizing images\n",
        "import math                                                                                      # Importing math module to perform mathematical operations\n",
        "import cv2                                                                                       # Importing openCV for image processing\n",
        "import seaborn as sns                                                                            # Importing seaborn to plot graphs\n",
        "\n",
        "\n",
        "# Tensorflow modules\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator                              # Importing the ImageDataGenerator for data augmentation\n",
        "from tensorflow.keras.models import Sequential                                                   # Importing the sequential module to define a sequential model\n",
        "from tensorflow.keras.layers import Dense,Dropout,Flatten,Conv2D,MaxPooling2D,BatchNormalization # Defining all the layers to build our CNN Model\n",
        "from tensorflow.keras.optimizers import Adam,SGD                                                 # Importing the optimizers which can be used in our model\n",
        "from sklearn import preprocessing                                                                # Importing the preprocessing module to preprocess the data\n",
        "from sklearn.model_selection import train_test_split                                             # Importing train_test_split function to split the data into train and test\n",
        "from sklearn.metrics import confusion_matrix                                                     # Importing confusion_matrix to plot the confusion matrix\n",
        "\n",
        "# Display images using OpenCV\n",
        "from google.colab.patches import cv2_imshow                                                      # Importing cv2_imshow from google.patches to display images\n",
        "\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oq-hAEOAV4aZ"
      },
      "source": [
        "## Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1XztFCIActAb",
        "outputId": "63e2dc62-a0b9-4779-b339-f6bd5eca65f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Uncomment and run the below code if you are using google colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "c2q2QUVZtpFb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "outputId": "9414a97b-c02c-43b1-fa01-1148e55ffb4b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-b90a478d5890>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load the image file of the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbaseDir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'images.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Load the labels file of the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    432\u001b[0m         \u001b[0m_ZIP_SUFFIX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb'PK\\x05\\x06'\u001b[0m \u001b[0;31m# empty zip files start with this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMAGIC_PREFIX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m         \u001b[0mmagic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmagic\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No data left in file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "baseDir = '/content/drive/MyDrive/Colab Notebooks/Intro to Computer Vision Module/Project 5/'\n",
        "\n",
        "# Load the image file of the dataset\n",
        "images = np.load(baseDir + 'images.npy')\n",
        "\n",
        "# Load the labels file of the dataset\n",
        "labels = pd.read_csv(baseDir + 'Labels.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uE84hQU7CSZa"
      },
      "source": [
        "## Data Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57vwo75fcXbU"
      },
      "source": [
        "### Understand the shape of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S2F57JGGcbzz"
      },
      "outputs": [],
      "source": [
        "print(images.shape)\n",
        "print(labels.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYv5uX-MC9KC"
      },
      "source": [
        "## Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vf_sWYNOjDvK"
      },
      "source": [
        "- EDA is an important part of any project involving data.\n",
        "- It is important to investigate and understand the data better before building a model with it.\n",
        "- A few questions have been mentioned below which will help you understand the data better.\n",
        "- A thorough analysis of the data, in addition to the questions mentioned below, should be done."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4dZsdgujrtK"
      },
      "source": [
        "1. How are these different category plant images different from each other?\n",
        "2. Is the dataset provided an imbalance? (Check with using bar plots)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZxTvixIeBVIq"
      },
      "outputs": [],
      "source": [
        "cv2_imshow(images[5])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(images[5])"
      ],
      "metadata": {
        "id": "9wmyCQV07Y8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOvazq-OWpNB"
      },
      "source": [
        "## Data Pre-Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzpcKHaDWsG7"
      },
      "source": [
        "### Convert the BGR images to RGB images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9u82V2TWsuQ"
      },
      "outputs": [],
      "source": [
        "# Converting the images from BGR to RGB using cvtColor function of OpenCV\n",
        "for i in range(len(images)):\n",
        "  images[i] = cv2.cvtColor(images[i], cv2.COLOR_BGR2RGB)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_images(images,labels):\n",
        "  num_classes=10                                                                  # Number of Classes\n",
        "  categories=np.unique(labels)\n",
        "  keys=dict(labels['Label'])                                                      # Obtaing the unique classes from y_train\n",
        "  rows = 3                                                                        # Defining number of rows=3\n",
        "  cols = 4                                                                        # Defining number of columns=4\n",
        "  fig = plt.figure(figsize=(10, 8))                                               # Defining the figure size to 10x8\n",
        "  for i in range(cols):\n",
        "      for j in range(rows):\n",
        "          random_index = np.random.randint(0, len(labels))                        # Generating random indices from the data and plotting the images\n",
        "          ax = fig.add_subplot(rows, cols, i * rows + j + 1)                      # Adding subplots with 3 rows and 4 columns\n",
        "          ax.imshow(images[random_index, :])                                      # Plotting the image\n",
        "          ax.set_title(keys[random_index])\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "Dj5vMndY8BhQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_images(images,labels)"
      ],
      "metadata": {
        "id": "ecFijeSr8FeD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b> Checking for data imbalance"
      ],
      "metadata": {
        "id": "pN6sYDgv9ZmT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " sns.countplot(labels['Label'])\n",
        " plt.xticks(rotation='vertical')"
      ],
      "metadata": {
        "id": "rStJEPZW9b75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STMonBqiWxM5"
      },
      "source": [
        "### Resize the images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pESDU0AEMOFk"
      },
      "source": [
        "As the size of the images is large, it may be computationally expensive to train on these larger images; therefore, it is preferable to reduce the image size from 128 to 64."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJYZ4IpGkwre"
      },
      "outputs": [],
      "source": [
        "images_decreased=[]\n",
        "height = 64\n",
        "width = 64\n",
        "dimensions = (width, height)\n",
        "for i in range(len(images)):\n",
        "  images_decreased.append( cv2.resize(images[i], dimensions, interpolation=cv2.INTER_LINEAR))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(images_decreased[3])"
      ],
      "metadata": {
        "id": "LHJKx1ke9sln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdsVQb4umB0P"
      },
      "source": [
        "### Data Preparation for Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KljdsjFCmJIZ"
      },
      "source": [
        "- Before you proceed to build a model, you need to split the data into train, test, and validation to be able to evaluate the model that you build on the train data\n",
        "- You'll have to encode categorical features and scale the pixel values.\n",
        "- You will build a model using the train data and then check its performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQV0unTvM7XM"
      },
      "source": [
        "**Split the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "USifnEb_m85i"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(np.array(images_decreased),labels , test_size=0.1, random_state=42,stratify=labels)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_temp,y_temp , test_size=0.1, random_state=42,stratify=y_temp)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape,y_train.shape)\n",
        "print(X_val.shape,y_val.shape)\n",
        "print(X_test.shape,y_test.shape)"
      ],
      "metadata": {
        "id": "QszZRiT2_YWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAJ9B0wKNiY3"
      },
      "source": [
        "### Encode the target labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88OIAwNoEPfx"
      },
      "outputs": [],
      "source": [
        "# Convert labels from names to one hot vectors.\n",
        "# We have already used encoding methods like onehotencoder and labelencoder earlier so now we will be using a new encoding method called labelBinarizer.\n",
        "# Labelbinarizer works similar to onehotencoder\n",
        "\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "enc = LabelBinarizer()\n",
        "y_train_encoded = enc.fit_transform(y_train)\n",
        "y_val_encoded=enc.transform(y_val)\n",
        "y_test_encoded=enc.transform(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exJFCDSMNrEG"
      },
      "source": [
        "### Data Normalization\n",
        "Since the **image pixel values range from 0-255**, our method of normalization here will be **scaling** - we shall **divide all the pixel values by 255 to standardize the images to have values between 0-1.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVUuPJS9OB_U"
      },
      "outputs": [],
      "source": [
        "# Normalizing the image pixels\n",
        "X_train_normalized = X_train.astype('float32')/255.0\n",
        "X_val_normalized = X_val.astype('float32')/255.0\n",
        "X_test_normalized = X_test.astype('float32')/255.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9_M19L-OLng"
      },
      "source": [
        "## Model Building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w0fnV8yNKmYr"
      },
      "outputs": [],
      "source": [
        "# Intializing a sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# Adding first conv layer with 64 filters and kernel size 3x3 , padding 'same' provides the output size same as the input size\n",
        "# Input_shape denotes input image dimension of images\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding=\"same\", input_shape=(64, 64, 3)))\n",
        "\n",
        "# Adding max pooling to reduce the size of output of first conv layer\n",
        "model.add(MaxPooling2D((2, 2), padding = 'same'))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding=\"same\"))\n",
        "model.add(MaxPooling2D((2, 2), padding = 'same'))\n",
        "\n",
        "# flattening the output of the conv layer after max pooling to make it ready for creating dense connections\n",
        "model.add(Flatten())\n",
        "\n",
        "# Adding a fully connected dense layer with 100 neurons\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "# Adding the output layer with 10 neurons and activation functions as softmax since this is a multi-class classification problem\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Using SGD Optimizer\n",
        "# opt = SGD(learning_rate=0.01, momentum=0.9)\n",
        "opt=Adam()\n",
        "# Compile model\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Generating the summary of the model\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <b> Fitting the model on the train data"
      ],
      "metadata": {
        "id": "D2LZByX_Ehmq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history_1 = model.fit(\n",
        "            X_train_normalized, y_train_encoded,\n",
        "            epochs=30,\n",
        "            validation_data=(X_val_normalized,y_val_encoded),\n",
        "            batch_size=32,\n",
        "            verbose=2\n",
        ")"
      ],
      "metadata": {
        "id": "ZZjWnyYwEivQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations:**\n",
        "*   We can see from the above plot that **the training accuracy of the  model was good but the validation accuracy was not good.**\n",
        "*   The model seems to overfit on the data."
      ],
      "metadata": {
        "id": "YjvDmczlE3W2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model Evaluation**"
      ],
      "metadata": {
        "id": "OwADi56OEsnM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history_1.history['accuracy'])\n",
        "plt.plot(history_1.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "S6S2gIPdEsQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Evaluating the model on test data**"
      ],
      "metadata": {
        "id": "_4vuR78UFRDV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = model.evaluate(X_test_normalized, y_test_encoded, verbose=2)"
      ],
      "metadata": {
        "id": "pBuD7zyAFSc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Generating the predictions using test data**"
      ],
      "metadata": {
        "id": "GumAVb9TJaGN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Here we would get the output as probablities for each category\n",
        "y_pred=model.predict(X_test_normalized)"
      ],
      "metadata": {
        "id": "nltwOiDhJdFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "id": "lBs7vD6CJkvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Plotting the Confusion Matrix**"
      ],
      "metadata": {
        "id": "TBC60EILJiXM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   The Confusion matrix is also defined as an inbuilt function in the TensorFlow module, so we can use that for evaluating the classification model.\n",
        "*   The Confusion matrix expects categorical data as input. However, y_test_encoded is an encoded value, whereas y_pred has probabilities. So,we must retrieve the categorical values from the encoded values.\n",
        "*   We will use the `argmax()` function to obtain the maximum value over each category on both y_test_encoded and y_pred and obtain their respective classes."
      ],
      "metadata": {
        "id": "hwxjmWP6J74S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtaining the categorical values from y_test_encoded and y_pred\n",
        "y_pred_arg=np.argmax(y_pred,axis=1)\n",
        "y_test_arg=np.argmax(y_test_encoded,axis=1)\n",
        "\n",
        "# Plotting the Confusion Matrix using confusion matrix() function which is also predefined tensorflow module\n",
        "confusion_matrix = tf.math.confusion_matrix(y_test_arg,y_pred_arg)\n",
        "f, ax = plt.subplots(figsize=(10, 8))\n",
        "sns.heatmap(\n",
        "    confusion_matrix,\n",
        "    annot=True,\n",
        "    linewidths=.4,\n",
        "    fmt=\"d\",\n",
        "    square=True,\n",
        "    ax=ax\n",
        ")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1ExSTUEmKB75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b> Observations</b><br>\n",
        "- We observe that some of the classes are not predicted correctly.\n",
        "- In comparison to the rest, we can see that classes 0,3, and 4 are well classified.\n",
        "- We can also observe that classes 1,2,5,7 and 9 are mostly misclassified."
      ],
      "metadata": {
        "id": "198zEdvMKRGi"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNKUalx8Jcoi"
      },
      "source": [
        "## Model Performance Improvement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_oS4D_AXFqX"
      },
      "source": [
        "**Reducing the Learning Rate:**\n",
        "\n",
        "**Hint**: Use **ReduceLRonPlateau()** function that will be used to decrease the learning rate by some factor, if the loss is not decreasing for some time. This may start decreasing the loss at a smaller learning rate. There is a possibility that the loss may still not decrease. This may lead to executing the learning rate reduction again in an attempt to achieve a lower loss."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zU6vqL67bd5a"
      },
      "source": [
        "### **Data Augmentation**\n",
        "\n",
        "Remember, **data augmentation should not be used in the validation/test data set**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5cgkAz_YKcc"
      },
      "source": [
        "## Final Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3MjkGfHYOPn"
      },
      "source": [
        "Comment on the final model you have selected and use the same in the below code to visualize the image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IESvQ8UyYLSK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvDkLMO7YIdY"
      },
      "source": [
        "### Visualizing the prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iez7QKJBrHvE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eg2x8AyJ4oPR"
      },
      "source": [
        "## Actionable Insights and Business Recommendations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvq4_6CZYcrv"
      },
      "source": [
        "*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geC4LwwIYfS_"
      },
      "source": [
        "_____"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "4ZgcS1MyVGZp",
        "WCxSmokWEKUJ",
        "q_I9gQJMVWL_",
        "aZq8uFtOVfnm",
        "qqFzmTb0BKKW",
        "oq-hAEOAV4aZ",
        "uE84hQU7CSZa",
        "57vwo75fcXbU",
        "EYv5uX-MC9KC",
        "vOvazq-OWpNB",
        "hzpcKHaDWsG7",
        "STMonBqiWxM5",
        "LdsVQb4umB0P",
        "FAJ9B0wKNiY3",
        "exJFCDSMNrEG",
        "d9_M19L-OLng",
        "kNKUalx8Jcoi",
        "A5cgkAz_YKcc",
        "Eg2x8AyJ4oPR"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}